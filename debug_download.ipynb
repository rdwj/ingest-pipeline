{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug S3 Download Issues\n",
    "\n",
    "Diagnose why downloads are hanging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "import os\n",
    "\n",
    "S3_ENDPOINT = \"https://minio-api-minio.apps.meshtest.llnl.gov\"\n",
    "S3_BUCKET = \"kb-documents\"\n",
    "S3_PREFIX = \"data/\"\n",
    "S3_ACCESS_KEY = \"minioadmin\"\n",
    "S3_SECRET_KEY = \"minioadmin\"\n",
    "\n",
    "DOWNLOAD_PATH = \"/tmp/documents\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Just LIST files (don't download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress SSL warnings\n",
    "\n",
    "print(f\"Listing files in: {S3_ENDPOINT}/{S3_BUCKET}/{S3_PREFIX}\")\n",
    "\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url=S3_ENDPOINT,\n",
    "    aws_access_key_id=S3_ACCESS_KEY,\n",
    "    aws_secret_access_key=S3_SECRET_KEY,\n",
    "    verify=False\n",
    ")\n",
    "\n",
    "# List files\n",
    "paginator = s3_client.get_paginator('list_objects_v2')\n",
    "all_files = []\n",
    "\n",
    "for page in paginator.paginate(Bucket=S3_BUCKET, Prefix=S3_PREFIX):\n",
    "    if 'Contents' not in page:\n",
    "        continue\n",
    "    \n",
    "    for obj in page['Contents']:\n",
    "        if not obj['Key'].endswith('/'):\n",
    "            all_files.append({\n",
    "                'key': obj['Key'],\n",
    "                'size': obj['Size'],\n",
    "                'size_mb': obj['Size'] / (1024 * 1024)\n",
    "            })\n",
    "\n",
    "print(f\"\\nFound {len(all_files)} files\")\n",
    "print(f\"Total size: {sum(f['size'] for f in all_files) / (1024*1024):.2f} MB\")\n",
    "\n",
    "# Show largest files\n",
    "print(\"\\nLargest files:\")\n",
    "sorted_files = sorted(all_files, key=lambda x: x['size'], reverse=True)\n",
    "for f in sorted_files[:10]:\n",
    "    print(f\"  {f['size_mb']:.2f} MB - {f['key']}\")\n",
    "\n",
    "# Show first few files\n",
    "print(\"\\nFirst 10 files:\")\n",
    "for f in all_files[:10]:\n",
    "    print(f\"  {f['size_mb']:.4f} MB - {f['key']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Download ONE file with timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "from botocore.config import Config\n",
    "\n",
    "# Configure with explicit timeout\n",
    "config = Config(\n",
    "    connect_timeout=10,\n",
    "    read_timeout=30,\n",
    "    retries={'max_attempts': 3}\n",
    ")\n",
    "\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url=S3_ENDPOINT,\n",
    "    aws_access_key_id=S3_ACCESS_KEY,\n",
    "    aws_secret_access_key=S3_SECRET_KEY,\n",
    "    verify=False,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "if all_files:\n",
    "    test_file = all_files[0]\n",
    "    print(f\"Testing download: {test_file['key']}\")\n",
    "    print(f\"Size: {test_file['size_mb']:.4f} MB\")\n",
    "    \n",
    "    # Calculate local path\n",
    "    relative_path = test_file['key'][len(S3_PREFIX):] if S3_PREFIX else test_file['key']\n",
    "    local_file = os.path.join(DOWNLOAD_PATH, relative_path)\n",
    "    \n",
    "    # Create directory\n",
    "    Path(local_file).parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        start = time.time()\n",
    "        s3_client.download_file(S3_BUCKET, test_file['key'], local_file)\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        print(f\"SUCCESS: Downloaded in {elapsed:.2f} seconds\")\n",
    "        print(f\"Speed: {test_file['size_mb']/elapsed:.2f} MB/s\")\n",
    "        print(f\"Local file: {local_file}\")\n",
    "        print(f\"Exists: {os.path.exists(local_file)}\")\n",
    "        print(f\"Size: {os.path.getsize(local_file)} bytes\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Download first 10 files with progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Download first 10 files\n",
    "test_batch = all_files[:10]\n",
    "print(f\"Downloading {len(test_batch)} files...\\n\")\n",
    "\n",
    "successful = 0\n",
    "failed = 0\n",
    "\n",
    "for i, file_info in enumerate(test_batch, 1):\n",
    "    s3_key = file_info['key']\n",
    "    \n",
    "    # Calculate local path\n",
    "    relative_path = s3_key[len(S3_PREFIX):] if S3_PREFIX else s3_key\n",
    "    local_file = os.path.join(DOWNLOAD_PATH, relative_path)\n",
    "    \n",
    "    # Create directory\n",
    "    Path(local_file).parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(f\"[{i}/{len(test_batch)}] {s3_key} ({file_info['size_mb']:.4f} MB)\")\n",
    "    \n",
    "    try:\n",
    "        start = time.time()\n",
    "        s3_client.download_file(S3_BUCKET, s3_key, local_file)\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        print(f\"  SUCCESS in {elapsed:.2f}s ({file_info['size_mb']/elapsed:.2f} MB/s)\")\n",
    "        successful += 1\n",
    "    except Exception as e:\n",
    "        print(f\"  FAILED: {e}\")\n",
    "        failed += 1\n",
    "    \n",
    "    print()  # Blank line\n",
    "\n",
    "print(f\"\\nResults: {successful} successful, {failed} failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative: Use shell commands (might be faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If boto3 is too slow, try using s3cmd or aws cli via subprocess\n",
    "# First check if they're available:\n",
    "\n",
    "!which s3cmd\n",
    "!which aws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check what's already downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "if os.path.exists(DOWNLOAD_PATH):\n",
    "    # Count files already downloaded\n",
    "    result = subprocess.run(\n",
    "        f'find {DOWNLOAD_PATH} -type f | wc -l',\n",
    "        shell=True,\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Files already in {DOWNLOAD_PATH}: {result.stdout.strip()}\")\n",
    "    \n",
    "    # Show directory structure\n",
    "    print(f\"\\nDirectory structure:\")\n",
    "    !ls -lahR {DOWNLOAD_PATH} | head -50\n",
    "else:\n",
    "    print(f\"{DOWNLOAD_PATH} does not exist\")"
   ]
  }
 ],
 "metadata": {
  "kernelnel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
